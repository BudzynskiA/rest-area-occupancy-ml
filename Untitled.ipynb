{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e57a6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 24.02.2025 (F)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 25.02.2025 (M)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 26.02.2025 (F)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 27.02.2025 (M)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 28.02.2025 (F)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 01.03.2025 (M)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dn. 02.03.2025 (F)\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z. dnia 03.03.2025\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dnia 6.03.25\n",
      "Processing: Skoroszyt_badania.xlsx -> Dane z dnia 8.03.2025\n",
      "Processing: Tabela_MOP_czasy dostępności.xlsx -> 05.02.2025 środa\n",
      "Processing: Tabela_MOP_czasy dostępności.xlsx -> 09.02.2025 niedziela\n",
      "Processing: Tabela_MOP_czasy dostępności.xlsx -> 24.02.2025 poniedziałek\n",
      "✅ File saved: rest_area_occupancy_merged.csv\n",
      "✅ File saved: rest_area_occupancy_merged.xlsx\n",
      "🔢 Total number of rows in final dataset: 10740\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of Excel files to process\n",
    "files = [\"Skoroszyt_badania.xlsx\", \"Tabela_MOP_czasy dostępności.xlsx\"]\n",
    "all_dfs = []\n",
    "\n",
    "for file_path in files:\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    # Ignore sheets named \"wzór\" (template)\n",
    "    valid_sheets = [s for s in xls.sheet_names if s.strip().lower() != \"wzór\"]\n",
    "\n",
    "    for sheet_name in valid_sheets:\n",
    "        print(f\"Processing: {file_path} -> {sheet_name}\")\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)\n",
    "\n",
    "        # Identify time columns (such as 00:00, 1:00, 01:00:00)\n",
    "        hour_cols = [col for col in df.columns if (\":\" in str(col) and str(col).count(\":\") <= 2)]\n",
    "        meta_cols = [col for col in df.columns if col not in hour_cols]\n",
    "\n",
    "        if not hour_cols:\n",
    "            print(f\"⚠️ No time columns found in: {file_path} / {sheet_name}\")\n",
    "            continue\n",
    "\n",
    "        # Convert from wide to long format\n",
    "        df_long = df.melt(\n",
    "            id_vars=meta_cols,\n",
    "            value_vars=hour_cols,\n",
    "            var_name=\"Hour\",\n",
    "            value_name=\"Occupancy\"\n",
    "        )\n",
    "\n",
    "        # Drop empty or whitespace-only occupancy values\n",
    "        df_long = df_long[df_long[\"Occupancy\"].notna() & (df_long[\"Occupancy\"].str.strip() != \"\")]\n",
    "\n",
    "        # Add source information\n",
    "        df_long[\"File\"] = file_path\n",
    "        df_long[\"Sheet\"] = sheet_name\n",
    "\n",
    "        all_dfs.append(df_long)\n",
    "\n",
    "# Merge all processed sheets if any\n",
    "if all_dfs:\n",
    "    # Use the union of all columns, filling missing values with NaN\n",
    "    all_cols = set.union(*(set(df.columns) for df in all_dfs))\n",
    "    final_df = pd.concat([df.reindex(columns=all_cols) for df in all_dfs], ignore_index=True)\n",
    "\n",
    "    # Remove the \"File\" and \"Sheet\" columns if they exist\n",
    "    for col_to_drop in [\"File\", \"Sheet\"]:\n",
    "        if col_to_drop in final_df.columns:\n",
    "            final_df.drop(columns=[col_to_drop], inplace=True)\n",
    "\n",
    "    # Map letters to English descriptors: low/medium/high\n",
    "    unify_map = {\n",
    "        \"N\": \"low\",\n",
    "        \"S\": \"medium\",\n",
    "        \"Ś\": \"medium\",\n",
    "        \"D\": \"high\",\n",
    "        \"P\": \"high\"\n",
    "    }\n",
    "    final_df[\"Occupancy\"] = final_df[\"Occupancy\"].map(unify_map)\n",
    "\n",
    "    # Export to CSV\n",
    "    final_df.to_csv(\"rest_area_occupancy_merged.csv\", index=False)\n",
    "    print(\"✅ File saved: rest_area_occupancy_merged.csv\")\n",
    "\n",
    "    # Also export to Excel as a backup\n",
    "    final_df.to_excel(\"rest_area_occupancy_merged.xlsx\", index=False)\n",
    "    print(\"✅ File saved: rest_area_occupancy_merged.xlsx\")\n",
    "\n",
    "    print(\"🔢 Total number of rows in final dataset:\", len(final_df))\n",
    "else:\n",
    "    print(\"❌ No data found to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9126fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
